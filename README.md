# ğŸ“Š Churn Prediction - IBM Dataset (Kaggle)

Este projeto tem como objetivo prever a evasÃ£o de clientes (churn) utilizando um conjunto de dados disponibilizado pela IBM no Kaggle. Ao longo da anÃ¡lise, aplicamos diversas tÃ©cnicas de ciÃªncia de dados, desde a exploraÃ§Ã£o inicial atÃ© o ajuste fino do melhor modelo preditivo.

## ğŸ“š Bibliotecas Utilizadas

* Pandas
* NumPy
* Matplotlib / Pyplot
* Seaborn
* Scikit-learn
* Imbalanced-learn (imblearn.over_sampling)

## ğŸ“Œ Etapas do Projeto

1. Entendimento do Dataset

* Leitura e descriÃ§Ã£o do conjunto de dados
* IdentificaÃ§Ã£o de variÃ¡veis explicativas (features) e variÃ¡vel-alvo (target)
* VerificaÃ§Ã£o de tipos de dados e valores ausentes

2. AnÃ¡lises ExploratÃ³rias
   
* AnÃ¡lises univariadas: distribuiÃ§Ã£o das variÃ¡veis
* AnÃ¡lises bivariadas: relaÃ§Ã£o entre variÃ¡veis e o target
* CorrelaÃ§Ã£o entre variÃ¡veis numÃ©ricas
* GrÃ¡ficos com Seaborn e Matplotlib para apoio visual

3. PrÃ©-processamento
   
* TransformaÃ§Ã£o de variÃ¡veis categÃ³ricas do tipo object em variÃ¡veis dummies
* NormalizaÃ§Ã£o de dados numÃ©ricos (se necessÃ¡rio)
* Balanceamento da base com oversampling (via SMOTE) para tratar desbalanceamento entre classes
* DivisÃ£o entre conjunto de treino e teste

4. Modelagem

* CriaÃ§Ã£o e avaliaÃ§Ã£o de diferentes algoritmos de classificaÃ§Ã£o
* ComparaÃ§Ã£o de desempenho com base em mÃ©tricas como:
* Accuracy
* Precision
* Recall
* F1-score
* AUC-ROC

5. OtimizaÃ§Ã£o de HiperparÃ¢metros

* AplicaÃ§Ã£o de GridSearchCV no modelo com melhor desempenho
* Ajuste fino dos hiperparÃ¢metros (tuning)
* ReavaliaÃ§Ã£o do modelo apÃ³s ajuste

6. Salvamento do Modelo
   
ExportaÃ§Ã£o do modelo final treinado utilizando joblib ou pickle

## ğŸ“ Dataset

Fonte: Kaggle - IBM Telco Customer Churn (https://www.kaggle.com/datasets/blastchar/telco-customer-churn/data)

## âœ… Resultados

O modelo final apresentou uma boa capacidade de prever clientes com alta chance de churn, possibilitando a aplicaÃ§Ã£o prÃ¡tica em estratÃ©gias de retenÃ§Ã£o de clientes.
O modelo com maior acurÃ¡cia foi utilizando o Random Forest.

## ğŸš€ Como Rodar

* Clone este repositÃ³rio
* Instale os requisitos do projeto: requirements.txt
* execute o notebook principal "churn_prediction.ipynb"

## ğŸ¤ ContribuiÃ§Ãµes

Sinta-se Ã  vontade para abrir issues, sugerir melhorias ou criar pull requests!

## ğŸ‘¨â€ğŸ’» Autor

**Matheus Phillipe Carvalho Ferreira**
TransiÃ§Ã£o de carreira para Ã¡rea de dados â€¢ Entusiasta em aprendizado de mÃ¡quina e anÃ¡lise de dados

LinkedIn: https://www.linkedin.com/in/matheus-pcf

